# This file is automatically generated by pyo3_stub_gen
# ruff: noqa: E501, F401

import builtins
import numpy
import numpy.typing
import typing
from enum import Enum

class AddNoise:
    r"""
    Augmenter that allows different types of noise injection
    
    Noise types:
    
    - Uniform: Adds uniform noise within the given bounds given through the parameter `bounds`
    
    - Gaussian: Adds gaussian noise with the specified mean and standard deviation according to the corresponding parameters
    
    - Spike: Adds a spike in the series with a random magnitude (in the range specified by `bounds` of the standard deviation of the original time series
    
    - Slope: Adds a linear slope trend to the series with a random slope in the range specified by `bounds`
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class AmplitudePhasePerturbation:
    r"""
    This augmenter perturbs the frequency representation of each time series by adding Gaussian noise
    to the magnitude and phase of each frequency bin. 
    
    If `is_time_domain` is true, the input is first
    transformed to the frequency domain using FFT, the perturbation is applied, and then the result is
    transformed back to the time domain using IFFT.
    
    The standard deviations of the noise for magnitude
    and phase are controlled by `magnitude_std` and `phase_std`, respectively.
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Convolve:
    r"""
    Usage of this augmenter is to convolve time series data with a kernel
    
    The kernel can be flat or Gaussian, and the size of the kernel are the parameters
    
    The convolve operation is applied to each time series in the dataset, and smoothening is achieved
    by averaging the values in the kernel window over the time series data.
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Crop:
    r"""
    Augmenter that crops each series into a random continuous slice of specified `size`
    
    Also known as window slicing
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Dataset:
    r"""
    Holds multiple univariate time series with their labels
    
    Passed to the `augment_batch` function from augmenters
    """
    features: numpy.typing.NDArray[numpy.float64]
    labels: builtins.list[builtins.str]
    def __new__(cls, features:numpy.typing.NDArray[numpy.float64], labels:typing.Sequence[builtins.str]) -> Dataset: ...
    def set_features(self, features:numpy.typing.NDArray[numpy.float64]) -> None: ...
    def set_labels(self, labels:typing.Sequence[builtins.str]) -> None: ...

class Drift:
    r"""
    Drifts the value of a time series by a random value at each point in the series.
    
    The drift is linear between the points, bounded by `max_drift`.
    
    The number of drift points is specified by `n_drift_points`.
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Drop:
    r"""
    Augmenter that drops data points in series
    
    Drops `percentage` % of data points and replaces them with `default`
    
    When omitted `default = 0`
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class FrequencyMask:
    r"""
    This augmenter applies a frequency-domain mask to each time series, zeroing out a contiguous block of frequency bins.
    
    - If `is_time_domain` is true, the input is first transformed to the frequency domain using FFT, the mask is applied, and then the result is transformed back to the time domain using IFFT.
    
    The width of the mask is controlled by `mask_width`, and the masked region is chosen randomly for each sample.
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Jittering:
    r"""
    Augmenter that adds white gaussian noise of the specified standard deviation and a mean of 0
    
    A special case of the `AddNoise` augmenter
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Permutate:
    r"""
    Permutate time series
    
    First, slices each series into segments and then rearranges them randomly
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Pool:
    r"""
    Reduces the temporal resolution without changing the length by pooling multiple samples together
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class QualityBenchmarking:
    r"""
    Class to perform quality benchmarking of augmenters
    
    This module provides functionality to evaluate and compare the quality of different data augmentation techniques.
    
    Currently, it includes using the Dynamic Time Warping (DTW) algorithm to measure the similarity between original and augmented time series data.
    """
    @staticmethod
    def compute_dtw(a:typing.Sequence[builtins.float], b:typing.Sequence[builtins.float]) -> tuple[builtins.float, builtins.list[tuple[builtins.int, builtins.int]]]:
        r"""
        Implementation of Dynamic Time Warping (DTW) algorithm.
        
        This function computes the DTW distance between two sequences and returns the distance
        along with the optimal path.
        
        # Arguments
        
        * `a` - First sequence as a list[float].
        
        * `b` - Second sequence as a list[float].
        
        # Returns
        
        A tuple containing the DTW distance (float) and a list of tuples representing the
        optimal path as pairs of indices (int, int).
        """

class Quantize:
    r"""
    Quantize time series to a level set
    
    The level set is constructed by uniformly discretizing the range of all values in the series
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class RandomTimeWarpAugmenter:
    r"""
    Augmenter that applies random time warping to the dataset
    This augmenter randomly selects a window of the time series, specified by the `window_size` argument and applies a speed change to it.
    The speed change is defined by the `speed_ratio_range` argument, which specifies the minimum and maximum speed ratio.
    The speed ratio is a multiplier that affects how fast or slow the selected window is stretched or compressed.
    If the window size is 0 or larger than the time series length, the entire series is warped.
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Repeat:
    r"""
    Augmenter that repeats all data rows `n` times
    
    Resource intensive because the data needs to be copied `n` times
    
    Only works with `augment_batch` because the data needs to be cloned
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Resize:
    r"""
    Changes temporal resolution of time series by changing the length
    
    Does not interpolate values!
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Reverse:
    r"""
    Reverses time series
    
    The augmenter turns `[1, 2, 3]` to `[3, 2, 1]`
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Rotation:
    r"""
    Augmenter that rotates the data 180 degrees around `anchor`
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Scaling:
    r"""
    Augmenter that scales a time series with a random scalar within the range specified
    by `min_factor` (inclusive) and `max_factor` (inclusive)
    """
    name: builtins.str
    probability: builtins.float
    def augment_batch(self, dataset:pyfraug.Dataset, parallel:builtins.bool) -> None:
        r"""
        Augment a whole batch
        
        Parallelized when `parallell` is set
        """
    def augment_one(self, x:numpy.typing.NDArray[numpy.float64]) -> numpy.typing.NDArray[numpy.float64]:
        r"""
        Augment one time series
        
        When called, the augmenter will always augment the series no matter what the probability for this augmenter is
        """
    def set_probability(self, p:builtins.float) -> None:
        r"""
        By setting a probability with this function the augmenter will only augment
        a series in a batch with the specified probability
        """

class Transforms:
    r"""
    Class containing various frequency domain transforms for time series data.
    
    This module provides implementations of different frequency domain transforms such as Fast Fourier Transform (FFT) and Discrete Cosine Transform (DCT).
    
    These transforms can be used for various purposes, including feature extraction, noise reduction, and data
    compression in time series analysis.
    """
    @staticmethod
    def fft(dataset:Dataset, parallel:builtins.bool) -> Dataset:
        r"""
        Converts each real-valued time series in the dataset into its frequency domain representation,
        storing the result as interleaved real and imaginary parts: [re0, im0, re1, im1, ...]
        """
    @staticmethod
    def ifft(dataset:Dataset, parallel:builtins.bool) -> Dataset:
        r"""
        Reconstructs each time series from its frequency domain representation (interleaved real/imag parts).
        """
    @staticmethod
    def dct(dataset:Dataset, parallel:builtins.bool) -> Dataset:
        r"""
        Discrete Cosine Transform (DCT-II) for time series data.
        
        Converts each real-valued time series in the dataset into DCT coefficients (real, frequency representation)
        """
    @staticmethod
    def idct(dataset:Dataset, parallel:builtins.bool) -> Dataset:
        r"""
        Inverse Discrete Cosine Transform (DCT-III) for time series data.
        Reconstructs each time series from its DCT coefficients, recovering the original signal.
        """
    @staticmethod
    def compare_within_tolerance(original:Dataset, reconstructed:Dataset, tolerance:builtins.float) -> tuple[builtins.float, builtins.bool]:
        r"""
        Computes maximum absolute difference between two Datasets and check if all differences are within a tolerance.
        """

class ConvolveWindow(Enum):
    r"""
    Enum to specify the kernel window for the `Convolve` augmenter
    """
    Flat = ...
    Gaussian = ...

class NoiseType(Enum):
    r"""
    Enum to specify the noise type for the AddNoise augmenter
    """
    Uniform = ...
    Gaussian = ...
    Spike = ...
    Slope = ...

class PoolingMethod(Enum):
    r"""
    Enum to specify the pooling function for the `Pool` augmenter
    """
    Max = ...
    Min = ...
    Average = ...

